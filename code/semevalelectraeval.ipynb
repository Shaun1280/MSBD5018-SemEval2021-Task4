{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraForPreTraining, ElectraTokenizerFast, ElectraConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nltk in /root/miniconda3/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /root/miniconda3/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /root/miniconda3/lib/python3.8/site-packages (from nltk) (2023.10.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "\n",
    "# nltk.download('wordnet', os.path.abspath('../working'))\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "file_path = os.path.abspath(\"../working/corpora/wordnet.zip\")\n",
    "\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.dirname(file_path))\n",
    "    \n",
    "nltk.data.path.append('../working')\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With RecAdam fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-large-discriminator\")\n",
    "\n",
    "class JsonlDataset(Dataset):\n",
    "    def __init__(self, filename, is_test=False):\n",
    "        self.data = [json.loads(line) for line in open(filename, 'r', encoding='utf-8')]\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def getMerged(self, question, options, article):\n",
    "        return [\n",
    "            f\"{question.replace('@placeholder', options[i])} [SEP] {article}\" for i in range(5)\n",
    "        ]\n",
    "    \n",
    "    def getLabels(self, label):\n",
    "#         print([(0 if i == label else 1) for i in range(5)])\n",
    "        return torch.tensor([(0 if i == label else 1) for i in range(5)])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        article = item['article']\n",
    "        question = item['question']\n",
    "        options = [item[f'option_{i}'] for i in range(5)]\n",
    "        \n",
    "        merged = self.getMerged(question, options, article)\n",
    "        \n",
    "        _input = tokenizer(\n",
    "            merged,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = _input[\"input_ids\"]\n",
    "        attention_mask = _input[\"attention_mask\"]\n",
    "        \n",
    "        origin = f\"{question.replace('@placeholder', '[MASK]')} [SEP] {article}\"\n",
    "        \n",
    "        origin_ids = tokenizer(\n",
    "            origin,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        \n",
    "        option_position = (origin_ids == tokenizer.mask_token_id).nonzero().tolist()[0][1]\n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'article': article,\n",
    "                'question': question,\n",
    "                'options': options,\n",
    "                'input_ids': input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                'merged': merged,\n",
    "                'option_position': option_position\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'article': article,\n",
    "                'question': question,\n",
    "                'options': options,\n",
    "                'label': item['label'],\n",
    "                'input_ids': input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                'labels': self.getLabels(item['label']),\n",
    "                'merged': merged,\n",
    "                'option_position': option_position\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_test_dataset = JsonlDataset('../input/semevaldataset/trail_data/Task_1_Imperceptibility.jsonl')\n",
    "task1_test_loader = DataLoader(task1_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "task2_test_dataset = JsonlDataset('../input/semevaldataset/trail_data/Task_2_Nonspecificity.jsonl')\n",
    "task2_test_loader = DataLoader(task2_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            _input_ids = batch['input_ids'].to(device)\n",
    "            _labels = batch['labels']\n",
    "            _label = batch['label']\n",
    "            _attention_mask = batch['attention_mask'].to(device)\n",
    "            _option_position = batch['option_position']\n",
    "            \n",
    "            for i in range(_input_ids.shape[0]):\n",
    "                input_ids = _input_ids[i]\n",
    "                labels = _labels[i]\n",
    "                label = _label[i]\n",
    "                attention_mask = _attention_mask[i]\n",
    "                option_position = _option_position[i]\n",
    "                \n",
    "                # input_ids shape: torch.Size([5, 512])\n",
    "                # labels shape: torch.Size([5]\n",
    "                # print('input ids: ', input_ids.shape, 'labels: ', labels.shape)\n",
    "            \n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                \n",
    "                # logit shape: torch.Size([5, 512])\n",
    "                # print('logits: ', logits.shape)\n",
    "                \n",
    "                # probabilities = torch.sigmoid(logits)\n",
    "                probabilities = logits[:, option_position]\n",
    "                # print(probabilities, label)\n",
    "                \n",
    "                most_likely_idx = probabilities.argmin().item()\n",
    "                \n",
    "                # print(most_likely_idx, label)\n",
    "                correct += (most_likely_idx == label.item())\n",
    "                total += 1\n",
    "\n",
    "    print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1: \n",
      "0.896\n",
      "Task1 cross: \n",
      "0.926\n",
      "Task2: \n",
      "0.928\n",
      "Task2 cross: \n",
      "0.896\n"
     ]
    }
   ],
   "source": [
    "# config = ElectraConfig(\"google/electra-large-discriminator\")\n",
    "discriminator = ElectraForPreTraining.from_pretrained(\"../input/semevalmodelelectra/task1_electra_recadam_last.bin\")\n",
    "print('Task1: ')\n",
    "eval(discriminator, task1_test_loader)\n",
    "print('Task1 cross: ')\n",
    "eval(discriminator, task2_test_loader)\n",
    "\n",
    "discriminator = ElectraForPreTraining.from_pretrained(\"../input/semevalmodelelectra/task2_electra_recadam_last.bin\")\n",
    "print('Task2: ')\n",
    "eval(discriminator, task2_test_loader)\n",
    "print('Task2 cross: ')\n",
    "eval(discriminator, task1_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without any Fine tuning: Task1, Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForPreTraining: ['electra.embeddings_project.bias', 'electra.embeddings_project.weight']\n",
      "- This IS expected if you are initializing ElectraForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1: \n",
      "0.898\n",
      "Task2: \n",
      "0.923\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Task1, Cross1, Task2, Cross2\n",
    "discriminator = ElectraForPreTraining.from_pretrained(\"google/electra-large-discriminator\")\n",
    "\n",
    "print('Task1: ')\n",
    "eval(discriminator, task1_test_loader)\n",
    "print('Task2: ')\n",
    "eval(discriminator, task2_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonlDataset2(JsonlDataset):\n",
    "    def getMerged(self, question, options, article):\n",
    "        wordnet_meaning = []\n",
    "        for i in range(5):\n",
    "            synsets = wordnet.synsets(options[i])\n",
    "            if len(synsets):\n",
    "                wordnet_meaning.append(f\"{synsets[0].definition()}\")\n",
    "            else:\n",
    "                wordnet_meaning.append(\"\")\n",
    "        return [\n",
    "            f\"{question.replace('@placeholder', options[i])} [SEP] {wordnet_meaning[i]} [SEP] {article}\" for i in range(5)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_test_dataset = JsonlDataset2('../input/semevaldataset/trail_data/Task_1_Imperceptibility.jsonl')\n",
    "task1_test_loader = DataLoader(task1_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "task2_test_dataset = JsonlDataset2('../input/semevaldataset/trail_data/Task_2_Nonspecificity.jsonl')\n",
    "task2_test_loader = DataLoader(task2_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1, Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1: \n",
      "0.85\n",
      "Task2: \n",
      "0.895\n"
     ]
    }
   ],
   "source": [
    "print('Task1: ')\n",
    "eval(discriminator, task1_test_loader)\n",
    "print('Task2: ')\n",
    "eval(discriminator, task2_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4001729,
     "sourceId": 6986655,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4047988,
     "sourceId": 7036293,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
