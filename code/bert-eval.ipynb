{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.755275Z","iopub.status.busy":"2023-11-22T07:39:50.754863Z","iopub.status.idle":"2023-11-22T07:39:50.760320Z","shell.execute_reply":"2023-11-22T07:39:50.759240Z","shell.execute_reply.started":"2023-11-22T07:39:50.755245Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","np.object = object "]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.763199Z","iopub.status.busy":"2023-11-22T07:39:50.762456Z","iopub.status.idle":"2023-11-22T07:39:50.772828Z","shell.execute_reply":"2023-11-22T07:39:50.771958Z","shell.execute_reply.started":"2023-11-22T07:39:50.763164Z"},"trusted":true},"outputs":[],"source":["# arguments\n","input_max_len = 512\n","\n","batch_size = 4\n","\n","concat_options = [\"without-options\", \"options-in-between\", \"options-at-end\"]\n","concat_option_id = 0;\n","\n","bert_model = 'bert-large-uncased' # or 'bert-base-uncased'"]},{"cell_type":"markdown","metadata":{},"source":["# data preparation"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.774237Z","iopub.status.busy":"2023-11-22T07:39:50.773938Z","iopub.status.idle":"2023-11-22T07:39:50.784615Z","shell.execute_reply":"2023-11-22T07:39:50.783736Z","shell.execute_reply.started":"2023-11-22T07:39:50.774213Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","import torch\n","from torch.utils.data import DataLoader\n","import json"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.787758Z","iopub.status.busy":"2023-11-22T07:39:50.786823Z","iopub.status.idle":"2023-11-22T07:39:50.794996Z","shell.execute_reply":"2023-11-22T07:39:50.794087Z","shell.execute_reply.started":"2023-11-22T07:39:50.787733Z"},"trusted":true},"outputs":[],"source":["def concat_text(question, article, options, tag = concat_option_id):\n","    if (tag == 0):\n","        return question.replace(\"@placeholder\", '[MASK]') + ' [SEP] '+ article # 76.4 82.8; 77.3 81.1; 74.5 80.1 \n","    elif (tag == 1):\n","        return question.replace(\"@placeholder\", '[MASK]') + ' [SEP] ' +  ' '.join(options)  + ' [SEP] ' + article # 76 82.2; 69.6 69; 66.9 69.7 \n","    elif (tag == 2):\n","        return question.replace(\"@placeholder\", '[MASK]') + ' [SEP] ' + article + ' [SEP] ' +  ' '.join(options) # 76 83.1; 71.5 73.5; 68.6 77.1  "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.796390Z","iopub.status.busy":"2023-11-22T07:39:50.796139Z","iopub.status.idle":"2023-11-22T07:39:50.805260Z","shell.execute_reply":"2023-11-22T07:39:50.804440Z","shell.execute_reply.started":"2023-11-22T07:39:50.796369Z"},"trusted":true},"outputs":[],"source":["def read_examples(input_file):\n","    examples = []\n","    with open(input_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            json_line = json.loads(line.strip())\n","            article = json_line.get('article', '')\n","            label = json_line.get('label', '')\n","            question = json_line.get('question', '')\n","            options = [json_line.get(f'option_{i}', '') for i in range(5)]\n","            examples.append({\n","                \"text\" :  concat_text(question, article, options),\n","                \"options\" : options,\n","                \"label\" : int(label)\n","            })\n","    return examples"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.806589Z","iopub.status.busy":"2023-11-22T07:39:50.806249Z","iopub.status.idle":"2023-11-22T07:39:50.815521Z","shell.execute_reply":"2023-11-22T07:39:50.814568Z","shell.execute_reply.started":"2023-11-22T07:39:50.806567Z"},"trusted":true},"outputs":[],"source":["task_1_test_data_path = '../input/semevaldataset/trail_data/Task_1_Imperceptibility.jsonl'\n","task_2_test_data_path = '../input/semevaldataset/trail_data/Task_2_Nonspecificity.jsonl'"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.817435Z","iopub.status.busy":"2023-11-22T07:39:50.816703Z","iopub.status.idle":"2023-11-22T07:39:50.904150Z","shell.execute_reply":"2023-11-22T07:39:50.902999Z","shell.execute_reply.started":"2023-11-22T07:39:50.817410Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if _pandas_api.is_sparse(col):\n"]}],"source":["task_1_test_data = Dataset.from_pandas(pd.DataFrame(read_examples(task_1_test_data_path)))\n","task_2_test_data = Dataset.from_pandas(pd.DataFrame(read_examples(task_2_test_data_path)))"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.905862Z","iopub.status.busy":"2023-11-22T07:39:50.905555Z","iopub.status.idle":"2023-11-22T07:39:50.913411Z","shell.execute_reply":"2023-11-22T07:39:50.910657Z","shell.execute_reply.started":"2023-11-22T07:39:50.905837Z"},"trusted":true},"outputs":[],"source":["from transformers import BertTokenizer, BertForMaskedLM"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:50.923506Z","iopub.status.busy":"2023-11-22T07:39:50.923248Z","iopub.status.idle":"2023-11-22T07:39:51.074802Z","shell.execute_reply":"2023-11-22T07:39:51.073708Z","shell.execute_reply.started":"2023-11-22T07:39:50.923483Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(bert_model)  "]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:51.076294Z","iopub.status.busy":"2023-11-22T07:39:51.075965Z","iopub.status.idle":"2023-11-22T07:39:51.083806Z","shell.execute_reply":"2023-11-22T07:39:51.082834Z","shell.execute_reply.started":"2023-11-22T07:39:51.076269Z"},"trusted":true},"outputs":[],"source":["def get_feature(example):\n","    # Concatenate the question and article with the sep token\n","    \n","    # Convert the concatenated text to tokens\n","    inputs = tokenizer(example['text'], max_length=input_max_len, truncation=True, padding='max_length', return_attention_mask=True)\n","    \n","    labels = tokenizer(example['options'][example['label']],  \n","                       add_special_tokens=False,\n","                       return_attention_mask=False,\n","                       return_token_type_ids=False,\n","                       max_length=1,\n","                       truncation=True).input_ids\n","    \n","    options = []\n","    for w in example['options']:\n","        options.append(tokenizer(w, add_special_tokens=False,\n","                                   return_attention_mask=False,\n","                                   return_token_type_ids=False,\n","                                   max_length=1,\n","                                   truncation=True).input_ids[0])\n","            \n","    example[\"input_ids\"] = inputs.input_ids\n","    example[\"attention_mask\"] = inputs.attention_mask\n","    example[\"labels\"] = labels\n","    example[\"options\"] = options\n","    example[\"answer\"] = [example['label']]\n","\n","    return example"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:51.085313Z","iopub.status.busy":"2023-11-22T07:39:51.084935Z","iopub.status.idle":"2023-11-22T07:39:51.095245Z","shell.execute_reply":"2023-11-22T07:39:51.094299Z","shell.execute_reply.started":"2023-11-22T07:39:51.085289Z"},"trusted":true},"outputs":[],"source":["remove_columns=[\"text\", 'label']\n","columns = [\"input_ids\", \"attention_mask\", \"labels\", \"options\", \"answer\"]"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:39:51.096425Z","iopub.status.busy":"2023-11-22T07:39:51.096188Z","iopub.status.idle":"2023-11-22T07:40:20.055833Z","shell.execute_reply":"2023-11-22T07:40:20.054887Z","shell.execute_reply.started":"2023-11-22T07:39:51.096405Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57d935d8bf374593a697afcc3ffcfac5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f33e52f3cab747eca65c84fca10c3c5f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["task_1_test_tokenize = task_1_test_data.map(get_feature, remove_columns=remove_columns)\n","task_2_test_tokenize = task_2_test_data.map(get_feature, remove_columns=remove_columns)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:40:20.058089Z","iopub.status.busy":"2023-11-22T07:40:20.057291Z","iopub.status.idle":"2023-11-22T07:40:20.065771Z","shell.execute_reply":"2023-11-22T07:40:20.064843Z","shell.execute_reply.started":"2023-11-22T07:40:20.058049Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['options', 'input_ids', 'attention_mask', 'labels', 'answer'],\n","    num_rows: 1000\n","})"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["task_1_test_tokenize.set_format(type='torch', columns=columns)\n","task_2_test_tokenize.set_format(type='torch', columns=columns)\n","task_1_test_tokenize"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:40:20.067103Z","iopub.status.busy":"2023-11-22T07:40:20.066809Z","iopub.status.idle":"2023-11-22T07:40:20.076872Z","shell.execute_reply":"2023-11-22T07:40:20.075999Z","shell.execute_reply.started":"2023-11-22T07:40:20.067078Z"},"trusted":true},"outputs":[],"source":["task_1_test_dataloader = DataLoader(task_1_test_tokenize, batch_size=batch_size)\n","task_2_test_dataloader = DataLoader(task_2_test_tokenize, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["# eval"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:40:20.079146Z","iopub.status.busy":"2023-11-22T07:40:20.078798Z","iopub.status.idle":"2023-11-22T07:40:20.091364Z","shell.execute_reply":"2023-11-22T07:40:20.090536Z","shell.execute_reply.started":"2023-11-22T07:40:20.079115Z"},"trusted":true},"outputs":[],"source":["def eval(model, test_loader):\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    model = model.to(device)\n","    model.eval()\n","    \n","    total = 0\n","    correct = 0\n","    \n","    for i, batch in enumerate(test_loader):\n","        with torch.no_grad():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            \n","            gt = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            \n","            logits = model(input_ids, attention_mask=attention_mask).logits\n","            \n","            mask_token_indexes = torch.where(input_ids == tokenizer.mask_token_id)[1]\n","            # shape: [batch_size, vocab_size]\n","            mask_token_logits = logits[torch.arange(logits.shape[0]), mask_token_indexes, :]\n","            \n","            options = batch['options'].to(device)\n","            batch_range = torch.arange(options.shape[0]).unsqueeze(-1).repeat(1, options.shape[1])\n","            # advanced indexing\n","            option_logits = mask_token_logits[batch_range, options]\n","            # [[label1], [label2], [label3], [label4?]]\n","            top_token_indexes = torch.topk(option_logits, 1).indices.tolist() # label\n","            top_tokens = [[options[i, idx[0]]] for i, idx in enumerate(top_token_indexes)]  \n","            preds = tokenizer.batch_decode(top_tokens, skip_special_tokens=True)\n","            \n","            answers = [answer.item() for answer in batch['answer']]\n","            outputs = [idx[0] for idx in top_token_indexes]\n","            \n","            if i == 0:\n","                for i in range(input_ids.shape[0]):\n","                    print(f'expected: {gt[i]}({answers[i]}), output: {preds[i]}({outputs[i]})')\n","#                     print(\"expected: \", gt[i] , ``, \"\\t output: \", preds[i])\n","                    print('\\n')\n","\n","            total += len(gt)\n","            correct += sum(answers[i] == outputs[i] for i in range(len(answers)))\n","\n","    print(\"Accuracy: \", correct / total)\n","    print(\"\\n=================================================\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation without fine tuning"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:40:20.105734Z","iopub.status.busy":"2023-11-22T07:40:20.105472Z","iopub.status.idle":"2023-11-22T07:42:42.826953Z","shell.execute_reply":"2023-11-22T07:42:42.825987Z","shell.execute_reply.started":"2023-11-22T07:40:20.105712Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cc6648cee2244aab2df2db958179fad","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Task1: \n","expected: lost(2), output: lost(2)\n","\n","\n","expected: reputation(4), output: reputation(4)\n","\n","\n","expected: potentially(0), output: potentially(0)\n","\n","\n","expected: classic(2), output: classic(2)\n","\n","\n","Accuracy:  0.788\n","\n","=================================================\n","\n","Task2: \n","expected: tough(3), output: condition(0)\n","\n","\n","expected: district(1), output: district(1)\n","\n","\n","expected: team(2), output: team(2)\n","\n","\n","expected: hand(1), output: hand(1)\n","\n","\n","Accuracy:  0.859\n","\n","=================================================\n","\n"]}],"source":["model = BertForMaskedLM.from_pretrained(bert_model)\n","print(\"Task1: \")\n","eval(model, task_1_test_dataloader)\n","print(\"Task2: \")\n","eval(model, task_2_test_dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation Task1, Cross1, Task2, Cross2"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-11-22T07:42:42.828486Z","iopub.status.busy":"2023-11-22T07:42:42.828208Z","iopub.status.idle":"2023-11-22T07:42:42.833015Z","shell.execute_reply":"2023-11-22T07:42:42.832080Z","shell.execute_reply.started":"2023-11-22T07:42:42.828463Z"},"trusted":true},"outputs":[],"source":["model = BertForMaskedLM.from_pretrained('../input/semevalmodelbert/' + concat_options[concat_option_id] + '/task_1_checkpoint')\n","print(\"Task1: \")\n","eval(model, task_1_test_dataloader)\n","print(\"Task1 Cross: \")\n","eval(model, task_2_test_dataloader)\n","\n","model = BertForMaskedLM.from_pretrained('../input/semevalmodelbert/' + concat_options[concat_option_id] + '/task_2_checkpoint')\n","print(\"Task2: \")\n","eval(model, task_2_test_dataloader)\n","print(\"Task2 Cross: \")\n","eval(model, task_1_test_dataloader)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4038932,"sourceId":7023520,"sourceType":"datasetVersion"},{"datasetId":4038953,"sourceId":7024411,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
