{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6986655,"sourceType":"datasetVersion","datasetId":4001729}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import ElectraForPreTraining, ElectraTokenizerFast\nfrom torch.optim import AdamW\n\nbatch_size = 4","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:56.692918Z","iopub.execute_input":"2023-11-23T07:15:56.693386Z","iopub.status.idle":"2023-11-23T07:15:56.698678Z","shell.execute_reply.started":"2023-11-23T07:15:56.693348Z","shell.execute_reply":"2023-11-23T07:15:56.697813Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Wordnet","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet', '../working')\n\nimport zipfile\nimport os\n\nfile_path = os.path.abspath(\"../working/corpora/wordnet.zip\")\n\nwith zipfile.ZipFile(file_path, 'r') as zip_ref:\n    zip_ref.extractall(os.path.dirname(file_path))\n    \nnltk.data.path.append('../working')\n\nfrom nltk.corpus import wordnet","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:56.700476Z","iopub.execute_input":"2023-11-23T07:15:56.700762Z","iopub.status.idle":"2023-11-23T07:15:56.983013Z","shell.execute_reply.started":"2023-11-23T07:15:56.700737Z","shell.execute_reply":"2023-11-23T07:15:56.981858Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to ../working...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Without any fine tuning","metadata":{}},{"cell_type":"markdown","source":"## Create test Dataset and Dataloader","metadata":{}},{"cell_type":"code","source":"tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-large-discriminator\")\n\nclass JsonlDataset(Dataset):\n    def __init__(self, filename, is_test=False):\n        self.data = [json.loads(line) for line in open(filename, 'r', encoding='utf-8')]\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.data)\n    \n    def getMerged(self, question, options, article):\n        return [\n            f\"{question.replace('@placeholder', options[i])} [SEP] {article}\" for i in range(5)\n        ]\n    \n    def getLabels(self, label):\n#         print([(0 if i == label else 1) for i in range(5)])\n        return torch.tensor([(0 if i == label else 1) for i in range(5)])\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        article = item['article']\n        question = item['question']\n        options = [item[f'option_{i}'] for i in range(5)]\n        \n        merged = self.getMerged(question, options, article)\n        \n        _input = tokenizer(\n            merged,\n            add_special_tokens=True,\n            max_length=512,\n            truncation=True,\n            padding='max_length',\n            return_tensors=\"pt\"\n        )\n        \n        input_ids = _input[\"input_ids\"]\n        attention_mask = _input[\"attention_mask\"]\n        \n        origin = f\"{question.replace('@placeholder', '[MASK]')} [SEP] {article}\"\n        \n        origin_ids = tokenizer(\n            origin,\n            add_special_tokens=True,\n            max_length=512,\n            truncation=True,\n            padding='max_length',\n            return_tensors=\"pt\"\n        )[\"input_ids\"]\n        \n        option_position = (origin_ids == tokenizer.mask_token_id).nonzero().tolist()[0][1]\n        \n        if self.is_test:\n            return {\n                'article': article,\n                'question': question,\n                'options': options,\n                'input_ids': input_ids,\n                \"attention_mask\": attention_mask,\n                'merged': merged,\n                'option_position': option_position\n            }\n        else:\n            return {\n                'article': article,\n                'question': question,\n                'options': options,\n                'label': item['label'],\n                'input_ids': input_ids,\n                \"attention_mask\": attention_mask,\n                'labels': self.getLabels(item['label']),\n                'merged': merged,\n                'option_position': option_position\n            }","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:56.984245Z","iopub.execute_input":"2023-11-23T07:15:56.984559Z","iopub.status.idle":"2023-11-23T07:15:57.072710Z","shell.execute_reply.started":"2023-11-23T07:15:56.984533Z","shell.execute_reply":"2023-11-23T07:15:57.071819Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"task1_test_dataset = JsonlDataset('../input/semevaldataset/trail_data/Task_1_Imperceptibility.jsonl')\ntask1_test_loader = DataLoader(task1_test_dataset, batch_size=batch_size, shuffle=True)\n\n\ntask2_test_dataset = JsonlDataset('../input/semevaldataset/trail_data/Task_2_Nonspecificity.jsonl')\ntask2_test_loader = DataLoader(task2_test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:57.075449Z","iopub.execute_input":"2023-11-23T07:15:57.075817Z","iopub.status.idle":"2023-11-23T07:15:57.116991Z","shell.execute_reply.started":"2023-11-23T07:15:57.075781Z","shell.execute_reply":"2023-11-23T07:15:57.116204Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def eval(model, test_loader):\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    model = model.to(device)\n    model.eval()\n    \n    total = 0\n    correct = 0\n    for i, batch in enumerate(test_loader):\n        with torch.no_grad():\n            _input_ids = batch['input_ids'].to(device)\n            _labels = batch['labels']\n            _label = batch['label']\n            _attention_mask = batch['attention_mask'].to(device)\n            _option_position = batch['option_position']\n            \n            for i in range(_input_ids.shape[0]):\n                input_ids = _input_ids[i]\n                labels = _labels[i]\n                label = _label[i]\n                attention_mask = _attention_mask[i]\n                option_position = _option_position[i]\n                \n                # input_ids shape: torch.Size([5, 512])\n                # labels shape: torch.Size([5]\n                # print('input ids: ', input_ids.shape, 'labels: ', labels.shape)\n            \n                outputs = model(input_ids, attention_mask=attention_mask)\n                logits = outputs.logits\n                \n                # logit shape: torch.Size([5, 512])\n                # print('logits: ', logits.shape)\n                \n                # probabilities = torch.sigmoid(logits)\n                probabilities = logits[:, option_position]\n                # print(probabilities, label)\n                \n                most_likely_idx = probabilities.argmin().item()\n                \n                # print(most_likely_idx, label)\n                correct += (most_likely_idx == label.item())\n                total += 1\n\n    print(correct / total)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:57.118064Z","iopub.execute_input":"2023-11-23T07:15:57.118349Z","iopub.status.idle":"2023-11-23T07:15:57.128363Z","shell.execute_reply.started":"2023-11-23T07:15:57.118323Z","shell.execute_reply":"2023-11-23T07:15:57.127337Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Without any Fine tuning: Task1, Task2","metadata":{}},{"cell_type":"code","source":"# Evaluation Task1, Cross1, Task2, Cross2\ndiscriminator = ElectraForPreTraining.from_pretrained(\"google/electra-large-discriminator\")\n\nprint('Task1: ')\neval(discriminator, task1_test_loader)\nprint('Task2: ')\neval(discriminator, task2_test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:15:57.129713Z","iopub.execute_input":"2023-11-23T07:15:57.130285Z","iopub.status.idle":"2023-11-23T07:25:59.927387Z","shell.execute_reply.started":"2023-11-23T07:15:57.130251Z","shell.execute_reply":"2023-11-23T07:25:59.926062Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForPreTraining: ['electra.embeddings_project.weight', 'electra.embeddings_project.bias']\n- This IS expected if you are initializing ElectraForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Task1: \n0.899\nTask2: \n0.923\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# With Wordnet","metadata":{}},{"cell_type":"code","source":"class JsonlDataset2(JsonlDataset):\n    def getMerged(self, question, options, article):\n        wordnet_meaning = []\n        for i in range(5):\n            synsets = wordnet.synsets(options[i])\n            if len(synsets):\n                wordnet_meaning.append(f\"{synsets[0].definition()}\")\n            else:\n                wordnet_meaning.append(\"\")\n        return [\n            f\"{question.replace('@placeholder', options[i])} [SEP] {wordnet_meaning[i]} [SEP] {article}\" for i in range(5)\n        ]","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:25:59.929199Z","iopub.execute_input":"2023-11-23T07:25:59.929538Z","iopub.status.idle":"2023-11-23T07:25:59.936030Z","shell.execute_reply.started":"2023-11-23T07:25:59.929503Z","shell.execute_reply":"2023-11-23T07:25:59.934923Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"task1_test_dataset = JsonlDataset2('../input/semevaldataset/trail_data/Task_1_Imperceptibility.jsonl')\ntask1_test_loader = DataLoader(task1_test_dataset, batch_size=batch_size, shuffle=True)\n\ntask2_test_dataset = JsonlDataset2('../input/semevaldataset/trail_data/Task_2_Nonspecificity.jsonl')\ntask2_test_loader = DataLoader(task2_test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:25:59.937317Z","iopub.execute_input":"2023-11-23T07:25:59.937619Z","iopub.status.idle":"2023-11-23T07:25:59.999016Z","shell.execute_reply.started":"2023-11-23T07:25:59.937593Z","shell.execute_reply":"2023-11-23T07:25:59.997994Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Task1, Task2","metadata":{}},{"cell_type":"code","source":"print('Task1: ')\neval(discriminator, task1_test_loader)\nprint('Task2: ')\neval(discriminator, task2_test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:26:00.000577Z","iopub.execute_input":"2023-11-23T07:26:00.000957Z","iopub.status.idle":"2023-11-23T07:36:01.003969Z","shell.execute_reply.started":"2023-11-23T07:26:00.000923Z","shell.execute_reply":"2023-11-23T07:36:01.002880Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Task1: \n0.85\nTask2: \n0.895\n","output_type":"stream"}]}]}